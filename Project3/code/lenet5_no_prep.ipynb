{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "%matplotlib inline\n",
    "import numpy as np \n",
    "import scipy.misc # to visualize only  \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import string\n",
    "# !pip install tensorflow\n",
    "import tensorflow as tf\n",
    "print(tf.test.gpu_device_name())\n",
    "# !pip install opencv-python\n",
    "import cv2\n",
    "import pandas as pd\n",
    "\n",
    "# !pip install keras\n",
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Concatenate, Input, concatenate, Lambda\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D, GlobalAveragePooling2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.optimizers import Adam, RMSprop, Adagrad, Nadam\n",
    "from math import exp\n",
    "import warnings\n",
    "import math\n",
    "import random\n",
    "import itertools\n",
    "# !pip install sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.layers import Layer\n",
    "from keras import activations\n",
    "from keras import utils\n",
    "from keras.models import Model\n",
    "from keras.layers import *\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.regularizers import l2\n",
    "\n",
    "from keras.models import model_from_json\n",
    "\n",
    "# !pip install xgboost\n",
    "import xgboost\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC,LinearSVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#cnn with xgboost\n",
    "import numpy as np\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Activation, Convolution2D, MaxPooling2D, Flatten, Input, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# LOAD LIBRARIES\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, AvgPool2D, BatchNormalization, Reshape\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "import numpy as np\n",
    "import cv2\n",
    "import sklearn.metrics as sklm\n",
    "\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.layers import Input, Flatten, Dense\n",
    "from keras.models import Model, load_model\n",
    "from keras.datasets import mnist\n",
    "\n",
    "from keras import backend as K\n",
    "img_dim_ordering = 'tf'\n",
    "K.set_image_dim_ordering(img_dim_ordering)\n",
    "\n",
    "train_images = pd.read_pickle('./train_images.pkl')\n",
    "train_labels = pd.read_csv('./train_labels.csv')\n",
    "test_images = pd.read_pickle('./test_images.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "x = train_images\n",
    "y = train_labels['Category'].values\n",
    "x = x.reshape(-1, 64, 64)\n",
    "y = y.reshape(-1, 1) \n",
    "x = np.uint8(x)\n",
    "y = np.uint8(y)\n",
    "\n",
    "\n",
    "for i in range(x.shape[0]):\n",
    "    ret,thresh = cv2.threshold(x[i],254,255,cv2.THRESH_BINARY)\n",
    "    x[i] = thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "img_dim = 64\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.2)\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0], img_dim, img_dim, 1)\n",
    "x_val = x_val.reshape(x_val.shape[0], img_dim, img_dim, 1)\n",
    "input_shape = (img_dim, img_dim, 1)\n",
    "\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_val = x_val.astype('float32')\n",
    "x_train /= 255\n",
    "x_val /= 255\n",
    "\n",
    "\n",
    "y_train = utils.to_categorical(y_train, num_classes)\n",
    "y_val = utils.to_categorical(y_val, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LeNet 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/envs/fastai/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /opt/conda/envs/fastai/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 64, 64, 6)         156       \n",
      "_________________________________________________________________\n",
      "average_pooling2d_1 (Average (None, 63, 63, 6)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 59, 59, 16)        2416      \n",
      "_________________________________________________________________\n",
      "average_pooling2d_2 (Average (None, 29, 29, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 25, 25, 120)       48120     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 75000)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 84)                6300084   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 84)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                850       \n",
      "=================================================================\n",
      "Total params: 6,351,626\n",
      "Trainable params: 6,351,626\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From /opt/conda/envs/fastai/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/10\n",
      "Learning rate:  0.001\n",
      "32000/32000 [==============================] - 178s 6ms/step - loss: 2.0584 - acc: 0.2414 - val_loss: 1.4711 - val_acc: 0.5021\n",
      "Epoch 2/10\n",
      "Learning rate:  0.001\n",
      "32000/32000 [==============================] - 177s 6ms/step - loss: 1.1537 - acc: 0.6182 - val_loss: 0.8874 - val_acc: 0.7147\n",
      "Epoch 3/10\n",
      "Learning rate:  0.001\n",
      "32000/32000 [==============================] - 177s 6ms/step - loss: 0.6260 - acc: 0.8004 - val_loss: 0.7936 - val_acc: 0.7541\n",
      "Epoch 4/10\n",
      "Learning rate:  0.001\n",
      "32000/32000 [==============================] - 178s 6ms/step - loss: 0.3357 - acc: 0.8919 - val_loss: 0.8374 - val_acc: 0.7604\n",
      "Epoch 5/10\n",
      "Learning rate:  0.001\n",
      "32000/32000 [==============================] - 180s 6ms/step - loss: 0.1795 - acc: 0.9406 - val_loss: 0.9796 - val_acc: 0.7601\n",
      "Epoch 6/10\n",
      "Learning rate:  0.001\n",
      "32000/32000 [==============================] - 185s 6ms/step - loss: 0.1358 - acc: 0.9554 - val_loss: 1.1250 - val_acc: 0.7609\n",
      "Epoch 7/10\n",
      "Learning rate:  0.001\n",
      "32000/32000 [==============================] - 185s 6ms/step - loss: 0.1013 - acc: 0.9668 - val_loss: 1.1930 - val_acc: 0.7549\n",
      "Epoch 8/10\n",
      "Learning rate:  0.001\n",
      "32000/32000 [==============================] - 185s 6ms/step - loss: 0.0885 - acc: 0.9713 - val_loss: 1.2045 - val_acc: 0.7560\n",
      "Epoch 9/10\n",
      "Learning rate:  0.001\n",
      "32000/32000 [==============================] - 185s 6ms/step - loss: 0.0737 - acc: 0.9754 - val_loss: 1.4204 - val_acc: 0.7560\n",
      "Epoch 10/10\n",
      "Learning rate:  0.001\n",
      "32000/32000 [==============================] - 185s 6ms/step - loss: 0.0677 - acc: 0.9781 - val_loss: 1.2470 - val_acc: 0.7672\n",
      "Test loss: 1.2470454453229904\n",
      "Test accuracy: 0.76725\n"
     ]
    }
   ],
   "source": [
    "num_classes = 10\n",
    "batch_size = 32\n",
    "epochs = 10\n",
    "\n",
    "def lr_schedule(epoch):\n",
    "    lr = 1e-3\n",
    "    if epoch > 20:\n",
    "        lr *= 1e-3\n",
    "    elif epoch > 15:\n",
    "        lr *= 1e-2\n",
    "    elif epoch > 10:\n",
    "        lr *= 1e-1\n",
    "    print('Learning rate: ', lr)\n",
    "    return lr\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(6, kernel_size=(5, 5), strides=(1, 1), activation='relu', input_shape=input_shape, padding=\"same\"))\n",
    "model.add(AveragePooling2D(pool_size=(2, 2), strides=(1, 1), padding='valid'))\n",
    "model.add(Conv2D(16, kernel_size=(5, 5), strides=(1, 1), activation='relu', padding='valid'))\n",
    "model.add(AveragePooling2D(pool_size=(2, 2), strides=(2, 2), padding='valid'))\n",
    "model.add(Conv2D(120, kernel_size=(5, 5), strides=(1, 1), activation='relu', padding='valid'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(84, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "\n",
    "lr_scheduler = LearningRateScheduler(lr_schedule)\n",
    "lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1),cooldown=0,patience=4,min_lr=0.5e-9)\n",
    "callbacks = [lr_reducer, lr_scheduler]\n",
    "\n",
    "\n",
    "history = model.fit(x_train, y_train, \n",
    "                              batch_size=batch_size, \n",
    "                              epochs = epochs, \n",
    "                    callbacks=callbacks,\n",
    "                    validation_data = (x_val,y_val))\n",
    "score = model.evaluate(x_val, y_val, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
