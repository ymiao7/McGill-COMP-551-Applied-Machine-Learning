{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import cv2 as cv\n",
    "import sys\n",
    "import csv\n",
    "import time\n",
    "import math\n",
    "import pickle\n",
    "import string\n",
    "import pyprind\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential, load_model\n",
    "from keras import backend as K\n",
    "from keras_adabound import AdaBound\n",
    "\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, LSTM, Input, AveragePooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ReduceLROnPlateau, LearningRateScheduler, TensorBoard\n",
    "import itertools\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images = pd.read_pickle('./test_images.pkl')\n",
    "train_images = pd.read_pickle('./train_images.pkl')\n",
    "train_labels = pd.read_csv('./train_labels.csv')\n",
    "\n",
    "# Preprocessing\n",
    "x = train_images\n",
    "y = train_labels['Category'].values\n",
    "x = x.reshape(-1, 64, 64)\n",
    "y = y.reshape(-1, 1) \n",
    "x = np.int64(x)\n",
    "y = np.int64(y)\n",
    "\n",
    "\n",
    "def preprocess(image):\n",
    "    connectivity = 4\n",
    "    img = image.astype(np.uint8)\n",
    "    _,thresh = cv.threshold(img,254,255,cv.THRESH_BINARY)\n",
    "\n",
    "    \n",
    "    img_blurred = cv.blur(img,(3,3))\n",
    "\n",
    "    _,thresh_blurred = cv.threshold(img_blurred,205,255,cv.THRESH_BINARY)    \n",
    "\n",
    "    output = cv.connectedComponentsWithStats(thresh_blurred, connectivity, cv.CV_32S)\n",
    "    n_components = output[0] - 1\n",
    "    stats = output[2][1:]\n",
    "    \n",
    "    # Too many high intensity parts, go without blur\n",
    "    if n_components >= 4:\n",
    "        output = cv.connectedComponentsWithStats(thresh, connectivity, cv.CV_32S)\n",
    "        n_components = output[0] - 1\n",
    "        stats = output[2][1:]\n",
    "    \n",
    "     \n",
    "    largest_component = np.array([])\n",
    "    largest_area = 0\n",
    "    largest_length = 0\n",
    "    largest_height = 0\n",
    "    for i in range(n_components):\n",
    "        \n",
    "        left = stats[i][0]\n",
    "        top = stats[i][1]\n",
    "        length = stats[i][2]\n",
    "        height = stats[i][3]\n",
    "        if max(length,height) >=32:\n",
    "            continue\n",
    "        area = max(length,height) ** 2 # for square bounding box\n",
    "        \n",
    "        if(area > largest_area):\n",
    "            largest_area = area\n",
    "            largest_length = length\n",
    "            largest_height = height\n",
    "            largest_component = thresh[top:height+top, left:left+length]\n",
    "\n",
    "            \n",
    "    result = np.zeros([64,64],dtype=np.uint8)\n",
    "    result[0:largest_height,0:largest_length] = result[0:largest_height,0:largest_length] + largest_component    \n",
    "    result = result[:32,:32]\n",
    "    return result\n",
    "\n",
    "x1 = np.zeros([x.shape[0],32,32],dtype=np.uint8)\n",
    "test1 = np.zeros([x.shape[0],32,32],dtype=np.uint8)\n",
    "for i in range(x.shape[0]):\n",
    "    x1[i] = preprocess(x[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(x1, y, test_size=0.2)\n",
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)\n",
    "Y_train = np.array(Y_train)\n",
    "Y_test = np.array(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(train_images_p).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = X_train.reshape(X_train.shape[0], -1)\n",
    "x_test = X_test.reshape(X_test.shape[0], -1)\n",
    "\n",
    "x_train = x_train/255.0\n",
    "x_test = x_test/255.0\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 101\n",
    "rfc = RandomForestClassifier(n_jobs=1, n_estimators=500, max_features='auto',random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_rfc = {\"n_estimators\": [500, 1000],\n",
    "              \"max_features\": [500, 1000, 'auto'],\n",
    "              \"criterion\": ['gini', 'entropy']}\n",
    "rfc_cv = GridSearchCV(rfc, param_grid = params_rfc, cv=2, verbose = 1, n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 12 candidates, totalling 24 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:  8.8min\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed: 17.8min\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  24 | elapsed: 21.1min remaining: 21.1min\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  24 | elapsed: 34.8min remaining: 20.9min\n",
      "[Parallel(n_jobs=-1)]: Done  18 out of  24 | elapsed: 35.0min remaining: 11.7min\n",
      "[Parallel(n_jobs=-1)]: Done  21 out of  24 | elapsed: 36.6min remaining:  5.2min\n",
      "[Parallel(n_jobs=-1)]: Done  24 out of  24 | elapsed: 50.7min remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  24 out of  24 | elapsed: 50.7min finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>criterion</th>\n",
       "      <th>max_features</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>mean_fit_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gini</td>\n",
       "      <td>1000</td>\n",
       "      <td>500</td>\n",
       "      <td>0.859406</td>\n",
       "      <td>0.000191</td>\n",
       "      <td>1015.995549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gini</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.859437</td>\n",
       "      <td>0.000277</td>\n",
       "      <td>2014.391321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>entropy</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.861781</td>\n",
       "      <td>0.003497</td>\n",
       "      <td>1762.063940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>entropy</td>\n",
       "      <td>1000</td>\n",
       "      <td>500</td>\n",
       "      <td>0.861844</td>\n",
       "      <td>0.004122</td>\n",
       "      <td>1021.501806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gini</td>\n",
       "      <td>500</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.873812</td>\n",
       "      <td>0.001282</td>\n",
       "      <td>1047.722257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gini</td>\n",
       "      <td>500</td>\n",
       "      <td>500</td>\n",
       "      <td>0.874031</td>\n",
       "      <td>0.001125</td>\n",
       "      <td>516.872876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>entropy</td>\n",
       "      <td>500</td>\n",
       "      <td>500</td>\n",
       "      <td>0.875531</td>\n",
       "      <td>0.001250</td>\n",
       "      <td>544.230008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>entropy</td>\n",
       "      <td>500</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.875687</td>\n",
       "      <td>0.000844</td>\n",
       "      <td>1079.722607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>entropy</td>\n",
       "      <td>auto</td>\n",
       "      <td>500</td>\n",
       "      <td>0.888437</td>\n",
       "      <td>0.000403</td>\n",
       "      <td>51.912349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>entropy</td>\n",
       "      <td>auto</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.888719</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>89.797717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gini</td>\n",
       "      <td>auto</td>\n",
       "      <td>500</td>\n",
       "      <td>0.889219</td>\n",
       "      <td>0.000254</td>\n",
       "      <td>51.178886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>gini</td>\n",
       "      <td>auto</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.889906</td>\n",
       "      <td>0.000129</td>\n",
       "      <td>98.969346</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   criterion max_features  n_estimators  mean_test_score  std_test_score  \\\n",
       "2       gini         1000           500         0.859406        0.000191   \n",
       "3       gini         1000          1000         0.859437        0.000277   \n",
       "9    entropy         1000          1000         0.861781        0.003497   \n",
       "8    entropy         1000           500         0.861844        0.004122   \n",
       "1       gini          500          1000         0.873812        0.001282   \n",
       "0       gini          500           500         0.874031        0.001125   \n",
       "6    entropy          500           500         0.875531        0.001250   \n",
       "7    entropy          500          1000         0.875687        0.000844   \n",
       "10   entropy         auto           500         0.888437        0.000403   \n",
       "11   entropy         auto          1000         0.888719        0.000059   \n",
       "4       gini         auto           500         0.889219        0.000254   \n",
       "5       gini         auto          1000         0.889906        0.000129   \n",
       "\n",
       "    mean_fit_time  \n",
       "2     1015.995549  \n",
       "3     2014.391321  \n",
       "9     1762.063940  \n",
       "8     1021.501806  \n",
       "1     1047.722257  \n",
       "0      516.872876  \n",
       "6      544.230008  \n",
       "7     1079.722607  \n",
       "10      51.912349  \n",
       "11      89.797717  \n",
       "4       51.178886  \n",
       "5       98.969346  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc_cv.fit(x_train, Y_train)\n",
    "cv_tabular(rfc_cv.cv_results_) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.898"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc_cv.score(x_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## k-NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=6)\n",
    "knn.fit(x_train,Y_train)\n",
    "knn.score(x_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(solver='lbfgs',C=1.0,verbose=1,n_jobs=-1,max_iter=800)\n",
    "lr.fit(x_train,Y_train)\n",
    "print('finish training')\n",
    "result = lr.predict(x_test).transpose().astype(int).flatten()\n",
    "print('finish validation')\n",
    "total = len(Y_test)\n",
    "correct = (result==Y_test).sum()\n",
    "accuracy = correct / total\n",
    "print('accuracy = ' + str(accuracy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
