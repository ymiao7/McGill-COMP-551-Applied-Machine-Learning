# -*- coding: utf-8 -*-
"""sr=0.5 experiment1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1brU27aAjre1qgv4mqeV5OwP0626UAk2D
"""

import keras
import tensorflow as tf
import os
import numpy as np
from tensorflow.python.keras.datasets import cifar10
from tensorflow.python.keras import backend as K
from tensorflow.python.keras.layers import Input, Conv2D, GlobalAveragePooling2D, Dense, BatchNormalization, Activation, MaxPooling2D,Dropout
# from keras.models import Model
from tensorflow.python.keras.models import Model
# from tensorflow.python.keras._impl import keras
# from tensorflow.python.keras._impl.keras.models import Model
from tensorflow.python.keras.layers import concatenate, add

from tensorflow.python.keras import optimizers,regularizers
from tensorflow.python.keras.preprocessing.image import ImageDataGenerator
from tensorflow.python.keras.initializers import he_normal
from tensorflow.python.keras.callbacks import LearningRateScheduler, TensorBoard, ModelCheckpoint,ReduceLROnPlateau

num_classes        = 10
batch_size         = 64         # 64 or 32 or other
epochs             = 100
CONCAT_AXIS=3
DATA_FORMAT='channels_last' # Theano:'channels_first' Tensorflow:'channels_last'

# load data
(x_train, y_train), (x_test, y_test) = cifar10.load_data()
y_train = keras.utils.to_categorical(y_train, num_classes)
y_test  = keras.utils.to_categorical(y_test, num_classes)
# x_train, x_test = color_preprocessing(x_train, x_test)
x_train = x_train.astype('float32')
x_test = x_test.astype('float32')
x_train /= 255
x_test /= 255

def fire_module(x,squeeze,expand,channel_axis,bypass_conv=0,bypass_simple=False,bypass_complex=False):
    s1 = Conv2D(squeeze,(1,1),padding='same')(x)# valid
    s1 = BatchNormalization()(s1)
    s1 = Activation('relu')(s1)

    e1 = Conv2D(expand,(1,1),padding='same')(s1)# valid
    e1 = BatchNormalization()(e1)
    e1 = Activation('relu')(e1)

    e3 = Conv2D(expand,(3,3),padding='same')(s1)
    e3 = BatchNormalization()(e3)
    e3 = Activation('relu')(e3)
    output = concatenate([e1,e3],axis=channel_axis)
    
    if bypass_simple:
        output = add([output,x])
    if bypass_complex:
        x = Conv2D(bypass_conv,(1,1),padding='same')(x) 
        x = BatchNormalization()(x)     
        x = Activation('relu')(x)
        output = add([output,x])
    return output



  
def squeezenet(img_input,classes=10):
    x = Conv2D(64, (3, 3), strides=(1, 1), padding='same')(img_input)# valid
    x = BatchNormalization()(x)
    x = Activation('relu')(x)
#     x = MaxPooling2D(pool_size=(3, 3), padding='same',data_format=DATA_FORMAT)(x)
    x = Dropout(0.2)(x)


    # fire 2,3,4
    x = fire_module(x,squeeze=64,expand=64,channel_axis=CONCAT_AXIS,bypass_conv=128,bypass_complex=True)
    x = fire_module(x,squeeze=64,expand=64,channel_axis=CONCAT_AXIS,bypass_simple=True)    
    x = fire_module(x,squeeze=128,expand=128,channel_axis=CONCAT_AXIS,bypass_conv=256,bypass_complex=True)
    x = MaxPooling2D(pool_size=(3, 3), padding='same',data_format=DATA_FORMAT)(x)
    x = Dropout(0.2)(x)
   
    # fire 5,6,7,8
    x = fire_module(x,squeeze=128,expand=128,channel_axis=CONCAT_AXIS,bypass_simple=True)       
    x = fire_module(x,squeeze=256,expand=256,channel_axis=CONCAT_AXIS,bypass_conv=512,bypass_complex=True)
    x = MaxPooling2D(pool_size=(3, 3), padding='same',data_format=DATA_FORMAT)(x)
    x = Dropout(0.2)(x)

    
    # fire 9
    x = fire_module(x,squeeze=256,expand=256,channel_axis=CONCAT_AXIS,bypass_simple=True)
    x = Dropout(0.5)(x)
    x = Conv2D(10, (1,1),strides=(1,1), padding='same')(x)
    x = BatchNormalization()(x)
    x = Activation('relu')(x)
#     x = Dropout(0.1)(x)
    x = GlobalAveragePooling2D()(x)
    x = BatchNormalization()(x)    
    out = Activation("softmax")(x)
    return out

  
img_input=Input(shape=(32,32,3))
output = squeezenet(img_input)
model=Model(img_input,output)
model.summary()
device_name = os.environ['COLAB_TPU_ADDR']
TPU_ADDRESS = 'grpc://' + device_name

tpu_model = tf.contrib.tpu.keras_to_tpu_model(
            model,
            strategy=tf.contrib.tpu.TPUDistributionStrategy(
              tf.contrib.cluster_resolver.TPUClusterResolver(TPU_ADDRESS)
            )
)
tpu_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

def lr_schedule(epoch):
    lr = 1e-3
    if epoch > 85:
        lr *= 1e-3
    elif epoch > 70:
        lr *= 1e-2
    elif epoch > 50:
        lr *= 1e-1
    print('Learning rate: ', lr)
    return lr
  
  
lr_scheduler = LearningRateScheduler(lr_schedule)
lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1),cooldown=0,patience=4,min_lr=0.5e-9)
callbacks = [lr_reducer, lr_scheduler]

# history = tpu_model.fit(x_train,y_train,batch_size=32,callbacks=callbacks,epochs=epochs,validation_data=(x_test,y_test))

datagen = ImageDataGenerator(
        featurewise_center=False,  # set input mean to 0 over the dataset
        samplewise_center=False,  # set each sample mean to 0
        featurewise_std_normalization=False,  # divide inputs by std of the dataset
        samplewise_std_normalization=False,  # divide each input by its std
        zca_whitening=False,  # apply ZCA whitening
        zca_epsilon=1e-06,  # epsilon for ZCA whitening
        rotation_range=20,  # randomly rotate images in the range (degrees, 0 to 180)
        # randomly shift images horizontally (fraction of total width)
        width_shift_range=0.1,
        # randomly shift images vertically (fraction of total height)
        height_shift_range=0.1,
        shear_range=0.5,  # set range for random shear
        zoom_range=(0.9,1.1),  # set range for random zoom
        channel_shift_range=0.,  # set range for random channel shifts
        # set mode for filling points outside the input boundaries
        fill_mode='nearest',
        cval=0.,  # value used for fill_mode = "constant"
        horizontal_flip=True,  # randomly flip images
        vertical_flip=False,  # randomly flip images
        # set rescaling factor (applied before any other transformation)
        rescale=None,
        # set function that will be applied on each input
        preprocessing_function=None,
        # image data format, either "channels_first" or "channels_last"
        data_format=None,
        # fraction of images reserved for validation (strictly between 0 and 1)
        validation_split=0.0)

datagen.fit(x_train)

# start training
history = tpu_model.fit_generator(datagen.flow(x_train, y_train,batch_size=batch_size),
                    steps_per_epoch=50000/128,
                    epochs=epochs,
                    callbacks=callbacks,
                    validation_data=(x_test, y_test))
score = tpu_model.evaluate(x_test, y_test, verbose=0)
print('Test loss:', score[0])
print('Test accuracy:', score[1])

import matplotlib.pyplot as plt
plt.plot(range(1, epochs + 1), history.history['acc'])
plt.plot(range(1, epochs +1), history.history['val_acc'])
plt.legend(['Training', 'Validation'])
plt.title("Model Accuracy")
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.show()

plt.figure()
plt.plot(history.history['loss'], color='b', label="Training loss")
plt.plot(history.history['val_loss'], color='r', label="validation loss")
legend = plt.legend(loc='best', shadow=True)

history.history